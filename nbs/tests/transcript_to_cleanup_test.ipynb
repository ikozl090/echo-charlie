{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b69357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311085e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import os\n",
    "\n",
    "BOSON_API_KEY = \"bai-Diz6JrS6rquzG1HSby-07fYX0AEgNJrCXKx0n6qr8F06ACSz\"\n",
    "client = OpenAI(api_key=BOSON_API_KEY, base_url=\"https://hackathon.boson.ai/v1\")\n",
    "\n",
    "def b64(path):\n",
    "    return base64.b64encode(open(path, \"rb\").read()).decode(\"utf-8\")\n",
    "\n",
    "reference_path = \"/Users/vishnou/Documents/echo-charlie/data/audio/chaplin_voice.wav\"\n",
    "reference_transcript = (\n",
    "    \"But we have lost the way. Greed has poisoned men’s souls, has barricaded the world with hate, has goose-stepped us into misery and bloodshed.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721678c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"Echo Charlie is a multimodal voice conversion system that takes a muted video and transforms it into a fully voiced performance.\n",
    "\n",
    "Here’s how it works.\n",
    "When you upload a video in the Streamlit app, Echo Charlie first samples a few key frames and extracts visual embeddings from each one. This helps identify who’s speaking and what they look like.\n",
    "\n",
    "Next, it searches the internal EchoDB — a ChromaDB-powered library of indexed voices — to find the closest matching reference audio. This ensures the generated speech sounds like the right person.\n",
    "\n",
    "Then, the lip-reading module steps in. Using the pre-trained LRS3 model, it decodes the silent mouth movements into raw text. That transcript is then cleaned up and punctuated by the Boson-hosted Qwen-32B large language model.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bde7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = '''\n",
    "After that, the Higgs speech model takes over. It combines the polished transcript with the retrieved speaker's voice from the vector database to generate a realistic voice track that matches the target speaker’s tone and rhythm.\n",
    "\n",
    "Finally, the Wav2Lip GAN model synchronizes it all — fusing the cloned audio with the original video to produce a perfectly lip-synced result. The silent clip now speaks naturally, as if it were never muted.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = \"\"\"Echo Charlie can be a powerful tool for film restoration and post-production — when audio tracks are lost, damaged, or need to be re-recorded without bringing actors back to the studio.\n",
    "It can also help recover archival footage, documentaries, or interviews where sound wasn’t captured properly, seamlessly restoring speech to match the original visuals.\n",
    "Beyond that, it opens creative possibilities for dubbing, accessibility, and automated voice recreation across languages and styles.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa361f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4 = \"\"\"In the Streamlit demo, you can explore every stage:\n",
    "Upload a muted video,\n",
    "Watch the lip-reading output,\n",
    "Review the cleaned transcript,\n",
    "Listen to the generated voice,\n",
    "And preview the final synced video.\n",
    "Echo Charlie — turning silence into seamless conversation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fccfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = client.chat.completions.create(\n",
    "    model=\"higgs-audio-generation-Hackathon\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": reference_transcript},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\n",
    "                \"type\": \"input_audio\",\n",
    "                \"input_audio\": {\"data\": b64(reference_path), \"format\": \"wav\"}\n",
    "            }],\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt_4},\n",
    "    ],\n",
    "    modalities=[\"text\", \"audio\"],\n",
    "    max_completion_tokens=4096,\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    "    stream=False,\n",
    "    stop=[\"<|eot_id|>\", \"<|end_of_text|>\", \"<|audio_eos|>\"],\n",
    "    extra_body={\"top_k\": 50},\n",
    ")\n",
    "\n",
    "audio_b64 = resp.choices[0].message.audio.data\n",
    "open(\"chaplin_narrated_3.wav\", \"wb\").write(base64.b64decode(audio_b64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879d943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boson-ai-hackathon (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
